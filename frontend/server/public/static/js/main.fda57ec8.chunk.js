(this["webpackJsonpyour-app"]=this["webpackJsonpyour-app"]||[]).push([[0],{111:function(e,t,a){e.exports=a.p+"static/media/detection.45312ae4.png"},112:function(e,t){e.exports="data:image/png;base64,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"},113:function(e,t,a){e.exports=a.p+"static/media/retail1.41f506ed.png"},114:function(e,t,a){e.exports=a.p+"static/media/retail2.3c48c7c9.png"},115:function(e,t,a){e.exports=a.p+"static/media/health1.6cbb4940.png"},116:function(e,t,a){e.exports=a.p+"static/media/manufacturing1.5ec57730.png"},117:function(e,t,a){e.exports=a.p+"static/media/vehicle1.48e1a479.gif"},118:function(e,t,a){e.exports=a.p+"static/media/agriculture1.901aa7fa.png"},122:function(e,t,a){e.exports=a(199)},130:function(e,t,a){},131:function(e,t,a){},199:function(e,t,a){"use strict";a.r(t);var n=a(0),i=a.n(n),o=a(24),s=a.n(o),l=(a(127),a(128),a(129),a(130),a(131),a(40)),r=a.n(l),c=a(41),m=a(11),h=a(8),u=a(7);class d extends i.a.Component{render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",null,i.a.createElement(u.h,{color:"indigo"},i.a.createElement("p",{className:"footer-copyright mb-0 py-3 text-center"},"\xa9 ",(new Date).getFullYear()," Copyright:",i.a.createElement("a",{href:"https://www.MDBootstrap.com"}," MDBootstrap.com ")))))}}var p=d;class g extends n.Component{constructor(...e){super(...e),this.state={collapseID:""},this.toggleCollapse=e=>()=>this.setState(t=>({collapseID:t.collapseID!==e?e:""})),this.closeCollapse=e=>()=>{var t=this.state.collapseID;window.scrollTo(0,0),t===e&&this.setState({collapseID:""})}}render(){var e=i.a.createElement("div",{id:"sidenav-overlay",style:{backgroundColor:"transparent"},onClick:this.toggleCollapse("mainNavbarCollapse")}),t=this.state.collapseID;return i.a.createElement("div",null,i.a.createElement(u.m,{color:"indigo",dark:!0,expand:"md",fixed:"top",scrolling:!0},i.a.createElement(u.n,{href:"/",className:"py-0 font-weight-bold"},i.a.createElement("strong",{className:"align-middle"},"CV Online")),i.a.createElement(u.p,{onClick:this.toggleCollapse("mainNavbarCollapse")}),i.a.createElement(u.c,{id:"mainNavbarCollapse",isOpen:t,navbar:!0},i.a.createElement(u.o,{right:!0},i.a.createElement(u.k,null,i.a.createElement(u.l,{exact:!0,to:"/homepage",onClick:this.closeCollapse("mainNavbarCollapse")},i.a.createElement("strong",null,"Home"))),i.a.createElement(u.k,null,i.a.createElement(u.d,null,i.a.createElement(u.g,{nav:!0,caret:!0},i.a.createElement("span",{className:"mr-2"},i.a.createElement("strong",null,"Topics"))),i.a.createElement(u.f,null,i.a.createElement(u.e,{onClick:()=>{this.setState({enter:!0})},href:"/topics/image-video-classification"},"Image/Video Classification"),i.a.createElement(u.e,{href:"/topics/object-detection"},"Object Detection"),i.a.createElement(u.e,{href:"/topics/instance-segmentation"},"Instance Segmentation"),i.a.createElement(u.e,{href:"/topics/image-video-enhancement"},"Image/Video Enhancement"),i.a.createElement(u.e,{href:"/topics/generative-adversarial-networks"},"Generative Adversarial Networks"),i.a.createElement(u.e,{href:"/topics/object-tracking"},"Object Tracking")))),i.a.createElement(u.k,null,i.a.createElement(u.d,null,i.a.createElement(u.g,{nav:!0,caret:!0},i.a.createElement("span",{className:"mr-2"},i.a.createElement("strong",null,"Applications"))),i.a.createElement(u.f,null,i.a.createElement(u.e,{href:"/applications/retail"},"Retail"),i.a.createElement(u.e,{href:"/applications/healthcare"},"Healthcare"),i.a.createElement(u.e,{href:"/applications/manufacturing"},"Manufacturing"),i.a.createElement(u.e,{href:"/applications/autonomous-vehicles"},"Autonomous Vehicles"),i.a.createElement(u.e,{href:"/applications/insurance"},"Insurance"),i.a.createElement(u.e,{href:"/applications/agriculture"},"Agriculture"),i.a.createElement(u.e,{href:"/applications/defense-and-security"},"Defense and Security"))))))),t&&e)}}var f=g;class E extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(f,null),i.a.createElement(h.a,{type:"polygon",bg:!0}),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Computer Vision"),i.a.createElement("p",null,"Computer vision is a field of artificial intelligence that trains computers to interpret and understand the visual world. Using digital images from cameras and videos and deep learning models, machines can accurately identify and classify objects \u2014 and then react to what they \u201csee.\u201d"),i.a.createElement("center",null,i.a.createElement("video",{controls:!0,src:"https://res.cloudinary.com/candicelin/video/upload/v1607826430/videoplayback_on3hth.mp4",type:"video/mp4"}))),i.a.createElement(p,null)))}}var b=E,v=a(32),y=a.n(v),w=a(47),k=a(205),C=a(120),x=a(206),T=a(98),I=a.n(T);class S extends i.a.Component{constructor(e){super(e),this.scrollToTop=()=>window.scrollTo(0,0),this.enterLoading=e=>{this.setState(({loadings:t})=>{var a=[...t];return a[e]=!0,{loadings:a,classify:!1,input:!0}}),setTimeout(()=>{this.setState(({loadings:t})=>{var a=[...t];return a[e]=!1,{loadings:a,classify:!0}})},6e3)},this.state={loadings:[],src:"",classify:!1,input:!1},this.handleInput=this.handleInput.bind(this),this.handleClassify=this.handleClassify.bind(this)}handleInput(e){var t=e.target.value;this.setState({src:t})}handleClassify(){var e=this;return Object(w.a)(y.a.mark((function t(){return y.a.wrap((function(t){for(;;)switch(t.prev=t.next){case 0:return t.next=2,r.a.get("".concat("http://localhost:8080","/classification"),{src:e.state.src});case 2:case"end":return t.stop()}}),t)})))()}render(){var e=this.state.loadings;return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"square",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",{id:"toc_0"},"Image Classification"),i.a.createElement("h2",{id:"toc_1"},"Introduction"),i.a.createElement("p",null,i.a.createElement("strong",null,"Motivation"),". In this section we will introduce the Image Classification problem, which is the task of assigning an input image one label from a fixed set of categories. This is one of the core problems in Computer Vision that, despite its simplicity, has a large variety of practical applications. Moreover, as we will see later in the course, many other seemingly distinct Computer Vision tasks (such as object detection, segmentation) can be reduced to image classification."),i.a.createElement("p",null,i.a.createElement("strong",null,"Example"),". For example, in the image below an image classification model takes a single image and assigns probabilities to 4 labels, cat, dog, hat, mug. As shown in the image, keep in mind that to a computer an image is represented as one large 3-dimensional array of numbers. In this example, the cat image is 248 pixels wide, 400 pixels tall, and has three color channels Red,Green,Blue (or RGB for short). Therefore, the image consists of 248 x 400 x 3 numbers, or a total of 297,600 numbers. Each number is an integer that ranges from 0 (black) to 255 (white). Our task is to turn this quarter of a million numbers into a single label, such as \u201ccat\u201d."),i.a.createElement("p",null,"The task in Image Classification is to predict a single label (or a distribution over labels as shown here to indicate our confidence) for a given image. Images are 3-dimensional arrays of integers from 0 to 255, of size Width x Height x 3. The 3 represents the three color channels Red, Green, Blue.",i.a.createElement("center",null,i.a.createElement("img",{src:"https://cs231n.github.io/assets/classify.png",alt:""}))),i.a.createElement("h2",{id:"toc_2"},"Supervised classification"),i.a.createElement("p",null,"Supervised classification is based on the idea that a user can select sample pixels in an image that are representative of specific classes and then direct the image processing software to use these training sites as references for the classification of all other pixels in the image. Training sites (also known as testing sets or input classes) are selected based on the knowledge of the user. The user also sets the bounds for how similar other pixels must be to group them together. These bounds are often set based on the spectral characteristics of the training area. The user also designates the number of classes that the image is classified into. Once a statistical characterization has been achieved for each information class, the image is then classified by examining the reflectance for each pixel and making a decision about which of the signatures it resembles most. Supervised classification uses classification algorithms and regression techniques to develop predictive models. The algorithms include linear regression, logistic regression, neural networks, decision tree, support vector machine, random forest, naive Bayes, and k-nearest neighbor."),i.a.createElement("h2",{id:"toc_3"},"Unsupervised classification"),i.a.createElement("p",null,"Unsupervised classification is where the outcomes (groupings of pixels with common characteristics) are based on the software analysis of an image without the user providing sample classes. The computer uses techniques to determine which pixels are related and groups them into classes. The user can specify which algorithm the software will use and the desired number of output classes but otherwise does not aid in the classification process. However, the user must have knowledge of the area being classified when the groupings of pixels with common characteristics produced by the computer have to be related to actual features on the ground. Some of the most common algorithms used in unsupervised learning include cluster analysis, anomaly detection, neural networks, and approaches for learning latent variable models."),i.a.createElement("h2",{id:"toc_4"},"dataset"),i.a.createElement("p",null,"COCO Sponsored by Microsoft is a large-scale object detection, segmentation, and captioning dataset. It contains images, bounding boxes and labels. There are two versions 2014 and 2017 that use the same images but different train, validation and test splits. COCO defines 91 classes but the data only uses 80 classes and some images don\u2019t have annotations. For the purpose of this project, we picked the 2017 validation dataset which is about 5000 images. Through COCO API, we found out that most images have more than one object with annotations for the same or different category. That led us to make use of this property by cropping the objects using the bounding boxes annotation and considering them as independent images in order to overcome the multi classes in the same image problem so we can feed the models with a single class image which makes it easier to classify. As a result, the number of images multiplied more than 20 times as shown in the chart below."),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glk9wuiwjvj30i30o60tg.jpg",alt:""}))),i.a.createElement("h2",{id:"toc_5"},"Structure for performing Image Classification"),i.a.createElement("ol",null,i.a.createElement("li",null,i.a.createElement("strong",null,i.a.createElement("em",null,"Image Pre-processing")),i.a.createElement("em",null,":"),"\xa0The aim of this process is to improve the image data (features) by suppressing unwanted distortions and enhancement of some important image features so that the computer vision models can benefit from this improved data to work on. Steps for image pre-processing includes",i.a.createElement("strong",null,"\xa0"),"Reading image, Resizing image, and Data Augmentation (Gray scaling of image, Reflection, Gaussian Blurring, Histogram, Equalization, Rotation, and Translation)."),i.a.createElement("li",null,i.a.createElement("strong",null,i.a.createElement("em",null,"Detection of an object")),i.a.createElement("em",null,":"),"\xa0Detection refers to the localization of an object which means the segmentation of the image and identifying the position of the object of interest."),i.a.createElement("li",null,i.a.createElement("strong",null,i.a.createElement("em",null,"Feature extraction and training")),i.a.createElement("em",null,":"),"\xa0This is a crucial step wherein statistical or deep learning methods are used to identify the most interesting patterns of the image, features that might be unique to a particular class and that will, later on, help the model to differentiate between different classes. This process where the model learns the features from the dataset is called model training."),i.a.createElement("li",null,i.a.createElement("strong",null,i.a.createElement("em",null,"Classification of the object")),i.a.createElement("em",null,":"),"\xa0This step categorizes detected objects into predefined classes by using a suitable classification technique that compares the image patterns with the target patterns.")),i.a.createElement("h2",{id:"toc_6"},"Convolutional Neural Network"),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glk9w55a1xj30rs09hju7.jpg",alt:""}))),i.a.createElement("p",null,"Convolutional Neural Network (CNN, or ConvNet) are a special kind of multi-layer neural networks, designed to recognize visual patterns directly from pixel images with minimal pre-processing. It is a special architecture of artificial neural networks. Convolutional neural network uses some of its features of visual cortex and have therefore achieved state of the art results in computer vision tasks. Convolutional neural networks are comprised of two very simple elements, namely convolutional layers and pooling layers. Although simple, there are near-infinite ways to arrange these layers for a given computer vision problem. The elements of a convolutional neural network, such as convolutional and pooling layers, are relatively straightforward to understand. The challenging part of using convolutional neural networks in practice is how to design model architectures that best use these simple elements. The reason why convolutional neural network is hugely popular is because of their architecture, the best thing is there is no need of feature extraction. The system learns to do feature extraction and the core concept is, it uses convolution of image and filters to generate invariant features which are passed on to the next layer. The features in next layer are convoluted with different filters to generate more invariant and abstract features and the process continues till it gets final feature/output which is invariant to occlusions. The most commonly used architectures of convolutional neural network are LeNet, AlexNet, ZFNet, GoogLeNet, VGGNet, and ResNet."),i.a.createElement("h2",null,"Classification Demo:"),i.a.createElement("center",null,i.a.createElement("div",{class:"input"},i.a.createElement(k.a,{placeholder:"Image src",id:"src",onChange:e=>this.handleInput(e)}),i.a.createElement(C.a,{type:"primary",icon:i.a.createElement(x.a,null),loading:e[1],onClick:()=>{this.enterLoading(1),this.handleClassify()}},"Classify")),i.a.createElement("br",null),this.state.input?i.a.createElement("img",{src:"https://res.cloudinary.com/candicelin/image/upload/v1607795113/sample.jpg"}):null),i.a.createElement("h3",null,"Result:"),i.a.createElement("center",null,this.state.classify?i.a.createElement("img",{src:I.a}):null)),i.a.createElement(p,null)))}}var j=S,N=a(111),R=a.n(N);class K extends i.a.Component{constructor(e){super(e),this.scrollToTop=()=>window.scrollTo(0,0),this.enterLoading=e=>{this.setState(({loadings:t})=>{var a=[...t];return a[e]=!0,{loadings:a,classify:!1,input:!0}}),setTimeout(()=>{this.setState(({loadings:t})=>{var a=[...t];return a[e]=!1,{loadings:a,classify:!0}})},6e3)},this.state={loadings:[],src:"",classify:!1,input:!1},this.handleInput=this.handleInput.bind(this),this.handleDetection=this.handleDetection.bind(this)}handleInput(e){var t=e.target.value;this.setState({src:t})}handleDetection(){return Object(w.a)(y.a.mark((function e(){return y.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:case"end":return e.stop()}}),e)})))()}render(){var e=this.state.loadings;return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"square",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",{id:"toc_0"},"Object Detection"),i.a.createElement("h2",{id:"toc_1"},"What is Object Recognition?"),i.a.createElement("p",null,"Object recognition is a general term to describe a collection of related computer vision tasks that involve identifying objects in digital photographs."),i.a.createElement("p",null,"Image classification involves predicting the class of one object in an image. Object localization refers to identifying the location of one or more objects in an image and drawing abounding box around their extent. Object detection combines these two tasks and localizes and classifies one or more objects in an image."),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glka8fav4dj31o00u07wi.jpg",alt:""}))),i.a.createElement("p",null,"As such, we can distinguish between these three computer vision tasks:"),i.a.createElement("ul",null,i.a.createElement("li",null,i.a.createElement("strong",null,"Image Classification"),": Predict the type or class of an object in an image.",i.a.createElement("ul",null,i.a.createElement("li",null,i.a.createElement("em",null,"Input"),": An image with a single object, such as a photograph."),i.a.createElement("li",null,i.a.createElement("em",null,"Output"),": A class label (e.g. one or more integers that are mapped to class labels)."))),i.a.createElement("li",null,i.a.createElement("strong",null,"Object Localization"),": Locate the presence of objects in an image and indicate their location with a bounding box.",i.a.createElement("ul",null,i.a.createElement("li",null,i.a.createElement("em",null,"Input"),": An image with one or more objects, such as a photograph."),i.a.createElement("li",null,i.a.createElement("em",null,"Output"),": One or more bounding boxes (e.g. defined by a point, width, and height)."))),i.a.createElement("li",null,i.a.createElement("strong",null,"Object Detection"),": Locate the presence of objects with a bounding box and types or classes of the located objects in an image.",i.a.createElement("ul",null,i.a.createElement("li",null,i.a.createElement("em",null,"Input"),": An image with one or more objects, such as a photograph."),i.a.createElement("li",null,i.a.createElement("em",null,"Output"),": One or more bounding boxes (e.g. defined by a point, width, and height), and a class label for each bounding box.")))),i.a.createElement("p",null,"One further extension to this breakdown of computer vision tasks is\xa0",i.a.createElement("em",null,"object segmentation"),", also called \u201cobject instance segmentation\u201d or \u201csemantic segmentation,\u201d where instances of recognized objects are indicated by highlighting the specific pixels of the object instead of a coarse bounding box."),i.a.createElement("p",null,"From this breakdown, we can see that object recognition refers to a suite of challenging computer vision tasks."),i.a.createElement("p",null,"Most of the recent innovations in image recognition problems have come as part of participation in the ILSVRC tasks."),i.a.createElement("p",null,"This is an annual academic competition with a separate challenge for each of these three problem types, with the intent of fostering independent and separate improvements at each level that can be leveraged more broadly. For example, see the list of the three corresponding task types below taken from the 2015 ILSVRC review paper:"),i.a.createElement("ul",null,i.a.createElement("li",null,"Image classification: Algorithms produce a list of object categories present in the image."),i.a.createElement("li",null,"Single-object localization: Algorithms produce a list of object categories present in the image, along with an axis-aligned bounding box indicating the position and scale of one instance of each object category."),i.a.createElement("li",null,"Object detection: Algorithms produce a list of object categories present in the image along with an axis-aligned bounding box indicating the position and scale of every instance of each object category.")),i.a.createElement("p",null,"We can see that \u201cSingle-object localization\u201d is a simpler version of the more broadly defined \u201cObject Localization,\u201d constraining the localization tasks to objects of one type within an image, which we may assume is an easier task."),i.a.createElement("p",null,"Below is an example comparing single object localization and object detection, taken from the ILSVRC paper. Note the difference in ground truth expectations in each case."),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glka6v8tiuj30iy0h0nbv.jpg",alt:""}))),i.a.createElement("h2",{id:"toc_2"},"Method"),i.a.createElement("h3",{id:"toc_3"},"R-CNN"),i.a.createElement("p",null,"The R-CNN was described in the 2014 paper by Ross Girshick, et al. from UC Berkeley titled \u201cRich feature hierarchies for accurate object detection and semantic segmentation.\u201d"),i.a.createElement("p",null,"It may have been one of the first large and successful application of convolutional neural networks to the problem of object localization, detection, and segmentation. The approach was demonstrated on benchmark datasets, achieving then state-of-the-art results on the VOC-2012 dataset and the 200-class ILSVRC-2013 object detection dataset."),i.a.createElement("p",null,"Their proposed R-CNN model is comprised of three modules; they are:"),i.a.createElement("ul",null,i.a.createElement("li",null,"Module 1: Region Proposal. Generate and extract category independent region proposals, e.g. candidate bounding boxes."),i.a.createElement("li",null,"Module 2: Feature Extractor. Extract feature from each candidate region, e.g. using a deep convolutional neural network."),i.a.createElement("li",null,"Module 3: Classifier. Classify features as one of the known class, e.g. linear SVM classifier model.")),i.a.createElement("p",null,"The architecture of the model is summarized in the image below, taken from the paper."),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glka9g4vrxj30rm09on2f.jpg",alt:""}))),i.a.createElement("p",null,"A computer vision technique is used to propose candidate regions or bounding boxes of potential objects in the image called \u201cselective search,\u201d although the flexibility of the design allows other region proposal algorithms to be used."),i.a.createElement("p",null,"The feature extractor used by the model was the AlexNet deep CNN that won the ILSVRC-2012 image classification competition. The output of the CNN was a 4,096 element vector that describes the contents of the image that is fed to a linear SVM for classification, specifically one SVM is trained for each known class."),i.a.createElement("p",null,"It is a relatively simple and straightforward application of CNNs to the problem of object localization and recognition. A downside of the approach is that it is slow, requiring a CNN-based feature extraction pass on each of the candidate regions generated by the region proposal algorithm. This is a problem as the paper describes the model operating upon approximately 2,000 proposed regions per image at test-time."),i.a.createElement("p",null,"Python (Caffe) and MatLab source code for R-CNN as described in the paper was made available in the R-CNN GitHub repository."),i.a.createElement("h3",{id:"toc_4"},"Fast R-CNN"),i.a.createElement("p",null,"Given the great success of R-CNN, Ross Girshick, then at Microsoft Research, proposed an extension to address the speed issues of R-CNN in a 2015 paper titled \u201cFast R-CNN.\u201d"),i.a.createElement("p",null,"The paper opens with a review of the limitations of R-CNN, which can be summarized as follows:"),i.a.createElement("ul",null,i.a.createElement("li",null,i.a.createElement("strong",null,"Training is a multi-stage pipeline"),". Involves the preparation and operation of three separate models."),i.a.createElement("li",null,i.a.createElement("strong",null,"Training is expensive in space and time"),". Training a deep CNN on so many region proposals per image is very slow."),i.a.createElement("li",null,i.a.createElement("strong",null,"Object detection is slow"),". Make predictions using a deep CNN on so many region proposals is very slow.")),i.a.createElement("p",null,"Fast R-CNN is proposed as a single model instead of a pipeline to learn and output regions and classifications directly."),i.a.createElement("p",null,"The architecture of the model takes the photograph a set of region proposals as input that are passed through a deep convolutional neural network. A pre-trained CNN, such as a VGG-16, is used for feature extraction. The end of the deep CNN is a custom layer called a Region of Interest Pooling Layer, or RoI Pooling, that extracts features specific for a given input candidate region."),i.a.createElement("p",null,"The output of the CNN is then interpreted by a fully connected layer then the model bifurcates into two outputs, one for the class prediction via a softmax layer, and another with a linear output for the bounding box. This process is then repeated multiple times for each region of interest in a given image."),i.a.createElement("p",null,"The architecture of the model is summarized in the image below, taken from the paper."),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glkaai6wokj30uw0cedrr.jpg",alt:""}))),i.a.createElement("h3",{id:"toc_5"},"YOLO"),i.a.createElement("p",null,"Another popular family of object recognition models is referred to collectively as YOLO or \u201cYou Only Look Once,\u201d developed by Joseph Redmon, et al."),i.a.createElement("p",null,"The R-CNN models may be generally more accurate, yet the YOLO family of models are fast, much faster than R-CNN, achieving object detection in real-time."),i.a.createElement("p",null,"The YOLO model was first described by Joseph Redmon, et al. in the 2015 paper titled \u201cYou Only Look Once: Unified, Real-Time Object Detection.\u201d Note that Ross Girshick, developer of R-CNN, was also an author and contributor to this work, then at Facebook AI Research."),i.a.createElement("p",null,"The approach involves a single neural network trained end to end that takes a photograph as input and predicts bounding boxes and class labels for each bounding box directly. The technique offers lower predictive accuracy (e.g. more localization errors), although operates at 45 frames per second and up to 155 frames per second for a speed-optimized version of the model."),i.a.createElement("p",null,"The model works by first splitting the input image into a grid of cells, where each cell is responsible for predicting a bounding box if the center of a bounding box falls within it. Each grid cell predicts a bounding box involving the x, y coordinate and the width and height and the confidence. A class prediction is also based on each cell."),i.a.createElement("p",null,"For example, an image may be divided into a 7\xd77 grid and each cell in the grid may predict 2 bounding boxes, resulting in 94 proposed bounding box predictions. The class probabilities map and the bounding boxes with confidences are then combined into a final set of bounding boxes and class labels. The image taken from the paper below summarizes the two outputs of the model."),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glkabb23s4j30ss0imtp8.jpg",alt:""}))),i.a.createElement("h2",null,"Object Detection Demo:"),i.a.createElement("center",null,i.a.createElement("div",{class:"input"},i.a.createElement(k.a,{placeholder:"Image src",id:"src",onChange:e=>this.handleInput(e)}),i.a.createElement(C.a,{type:"primary",icon:i.a.createElement(x.a,null),loading:e[1],onClick:()=>{this.enterLoading(1),this.handleDetection()}},"Detect")),i.a.createElement("br",null),this.state.input?i.a.createElement("img",{src:"https://res.cloudinary.com/candicelin/image/upload/v1607817705/dog_kqdssb.jpg"}):null),i.a.createElement("h3",null,"Result:"),i.a.createElement("center",null,this.state.classify?i.a.createElement("img",{src:R.a}):null)),i.a.createElement(p,null)))}}var q=K,U=a(112),F=a.n(U);class O extends i.a.Component{constructor(e){super(e),this.scrollToTop=()=>window.scrollTo(0,0),this.enterLoading=e=>{this.setState(({loadings:t})=>{var a=[...t];return a[e]=!0,{loadings:a,classify:!1,input:!0}}),setTimeout(()=>{this.setState(({loadings:t})=>{var a=[...t];return a[e]=!1,{loadings:a,classify:!0}})},6e3)},this.state={loadings:[],src:"",classify:!1,input:!1},this.handleInput=this.handleInput.bind(this),this.handleSegmentation=this.handleSegmentation.bind(this)}handleInput(e){var t=e.target.value;this.setState({src:t})}handleSegmentation(){return Object(w.a)(y.a.mark((function e(){return y.a.wrap((function(e){for(;;)switch(e.prev=e.next){case 0:case"end":return e.stop()}}),e)})))()}render(){var e=this.state.loadings;return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"square",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",{id:"toc_0"},"Instance Segmentation"),i.a.createElement("h2",{id:"toc_1"},"Introduction"),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glkaevsm9xj30rq0bkjza.jpg",alt:""}))),i.a.createElement("p",null,"Instance segmentation is popular image processing task, to understand this technique we must first understand it\u2019s subtasks."),i.a.createElement("p",null,i.a.createElement("strong",null,i.a.createElement("em",null,"Classification")),"\xa0is categorization process, where each instance, in our case object in image is being labeled with information what it is and score describing weight of prediction in percentage."),i.a.createElement("p",null,i.a.createElement("strong",null,i.a.createElement("em",null,"Object Detection\xa0")),"extends classification for multiple objects in one image as well as their detection, it is usually described in results as bounding boxes."),i.a.createElement("p",null,i.a.createElement("strong",null,i.a.createElement("em",null,"Semantic Segmentation")),"\xa0in nutshell makes prediction for each pixel of image to decide which class, in result we can obtain layers of each present class in image, for example as if you wanted extract human from image in photoshop."),i.a.createElement("p",null,"Finally\xa0",i.a.createElement("strong",null,i.a.createElement("em",null,"Instance Segmentation\xa0")),"consist of all previously mentioned tasks with modification for semantic segmentation to apply locally for each object found by object detection and each individual instance of class."),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glkada5aw2j30ro0ksdsm.jpg",alt:""}))),i.a.createElement("h2",{id:"toc_2"},"Examples"),i.a.createElement("p",null,"Instance segmentation results:",i.a.createElement("br",null),i.a.createElement("center",null,i.a.createElement("img",{src:"https://tryolabs.com/blog/images/blog/post-images/computer-vision-guide/instance-segmentation-beatles.aef0d5b6.png",alt:""}))),i.a.createElement("p",null,"You can see in the image above how the instance segmentation algorithm finds masks for the four Beatles and some cars (although the result is incomplete, especially where it comes to Lennon)."),i.a.createElement("p",null,"Such results would be very expensive if the tasks were carried out manually, but the technology makes it easy to achieve them. In France, the law prohibits exposing children in the media without the explicit consent of their parents. Using instance segmentation techniques, it\u2019s possible to blur out young children\u2019s faces on television or in film, when they are interviewed or captured outdoors, as may be the case during student strikes."),i.a.createElement("p",null,"Brain Tumor MRI and corresponding mask:",i.a.createElement("br",null),i.a.createElement("center",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glk7b81arcj312w0nc13b.jpg",alt:"Brain Tumor MRI and corresponding mask"}))),i.a.createElement("h2",{id:"toc_3"},"Methods"),i.a.createElement("h3",{id:"toc_4"},"Mask Faster R-CNN"),i.a.createElement("p",null,"In this article we will focus only on archetype of\xa0",i.a.createElement("a",{href:"https://arxiv.org/abs/1506.01497"},"Faster R-CNN"),"\xa0version, which had many predecessors, for history fans or those interseted more in R-CNN achitecture\xa0",i.a.createElement("a",{href:"https://towardsdatascience.com/instance-segmentation-using-mask-r-cnn-7f77bdd46abd"},"this article"),"\xa0is recommended. Now we will generally describe parts of this architecture."),i.a.createElement("p",null,i.a.createElement("strong",null,"Backbone\xa0"),"is CNN which transforms input image into features, which are further used by other components. It usually uses well known CNN architectures such as ResNet, VGG, ConvNet, etc.. Nowadays ResNet is one of the most popular especially with\xa0",i.a.createElement("a",{href:"https://arxiv.org/pdf/1612.03144.pdf"},"Feature Pyramid Network modification"),"."),i.a.createElement("p",null,i.a.createElement("strong",null,"RPN"),", Region Proposal Network is trained to detect objects on features obtained from backbone, objects are detected in rectangular areas, which can be modified to be found in various sizes and side size ratios (1:2, 1:1, 2:1). Outputs are anchors described by starting coordinates and sizes."),i.a.createElement("p",null,i.a.createElement("strong",null,"ROI Pooling"),", because Regions of Interest from features and anchors have various sizes and shapes, it would be necessary to train following Neural Network parts for each configuration, which is time and space consuming. For this case there is workaround by ROI Pooling and Align, which transform shape and size of region by pooling and bilinear interpolation method to be uniform for all."),i.a.createElement("p",null,i.a.createElement("strong",null,"Classifier"),"\xa0takes ROI Pooling output features as input and labels instance of object with evaluating score of prediction."),i.a.createElement("p",null,i.a.createElement("a",{href:"https://arxiv.org/pdf/1703.06870.pdf"},i.a.createElement("strong",null,"Mask R-CNN")),"\xa0is extension of Faster R-CNN, which works as branch parallel with classifier and takes the same inputs and uses them to predict masks of objects."),i.a.createElement("p",null,"In summary outputs of this network are bounding boxes, classes, scores and masks of predicted objects."),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glkae840jdj30kx0fxq5f.jpg",alt:""}))),i.a.createElement("h2",null,"Instance Segmentation Demo:"),i.a.createElement("center",null,i.a.createElement("div",{class:"input"},i.a.createElement(k.a,{placeholder:"Image src",id:"src",onChange:e=>this.handleInput(e)}),i.a.createElement(C.a,{type:"primary",icon:i.a.createElement(x.a,null),loading:e[1],onClick:()=>{this.enterLoading(1),this.handleSegmentation()}},"Segmentate")),i.a.createElement("br",null),this.state.input?i.a.createElement("img",{src:"https://res.cloudinary.com/candicelin/image/upload/v1607797724/timg-2_puhqmo.jpg"}):null),i.a.createElement("h3",null,"Result:"),i.a.createElement("center",null,this.state.classify?i.a.createElement("img",{src:F.a}):null)),i.a.createElement(p,null)))}}var A=O;class V extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"square",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",{id:"toc_0"},"Image Restoration"),i.a.createElement("h2",{id:"toc_1"},"Introduction"),i.a.createElement("div",{align:"center"},i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1gk6hhf7dxtj319d0g7dt9.jpg",width:"50%",alt:""}),i.a.createElement("small",null,i.a.createElement("center",null,"Example 1: Image Inpainting"))),i.a.createElement("p",null,"Image restoration deems to reconstruct or recover a original image from degraded image by utilizing a priori knowledge of the degradation phenomenon which is also called as ill-posed inverse problem. In image restoration problem or ill-posed inverse problem, the information loss due to image acquisition and transmission is restored based on some constraints which are suitable for natural images and medical images."),i.a.createElement("p",null,"Image restoration is the operation of taking a corrupt/noisy image and estimating the clean, original image. Corruption may come in many forms such as motion blur, noise and camera mis-focus.[1] Image restoration is performed by reversing the process that blurred the image and such is performed by imaging a point source and use the point source image, which is called the Point Spread Function (PSF) to restore the image information lost to the blurring process."),i.a.createElement("p",null,"Image restoration is different from image enhancement in that the latter is designed to emphasize features of the image that make the image more pleasing to the observer, but not necessarily to produce realistic data from a scientific point of view. Image enhancement techniques (like contrast stretching or de-blurring by a nearest neighbor procedure) provided by imaging packages use no a priori model of the process that created the image."),i.a.createElement("p",null,"With image enhancement noise can effectively be removed by sacrificing some resolution, but this is not acceptable in many applications. In a fluorescence microscope, resolution in the z-direction is bad as it is. More advanced image processing techniques must be applied to recover the object."),i.a.createElement("p",null,"We will show you some interesting examples of image restoration."),i.a.createElement("div",{align:"center"},i.a.createElement("iframe",{width:"641",height:"361",src:"https://www.youtube.com/embed/8DPHSwpDNVc",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0}),i.a.createElement("small",null,i.a.createElement("center",null,"Example 2: Image Super-Resolution"))),i.a.createElement("h2",{id:"toc_2"},"Degradations"),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glkamdje9pj30hk0dc40f.jpg",alt:""}))),i.a.createElement("h2",{id:"toc_3"},"Examples"),i.a.createElement("p",null,i.a.createElement("strong",null,"Old Photo Restoration")),i.a.createElement("center",null,i.a.createElement("p",null,i.a.createElement("img",{src:"https://tva1.sinaimg.cn/large/0081Kckwgy1glkasdmyc2j30j4066af0.jpg",alt:""})))),i.a.createElement(p,null)))}}var L=V;class J extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"square",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Example Title"),i.a.createElement("p",null,"Example text")),i.a.createElement(p,null)))}}var G=J;class z extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"square",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Example Title"),i.a.createElement("p",null,"Example text")),i.a.createElement(p,null)))}}var B=z,P=a(113),Q=a.n(P),W=a(114),D=a.n(W);class Z extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(f,null),i.a.createElement(h.a,{type:"fountain",bg:!0}),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Retail"),i.a.createElement("div",{class:"introduction"},"The use of computer vision in the retail sector has been one of the most important technological trends in recent years. Below, you\u2019ll be introduced to some very common use cases. "),i.a.createElement("h2",null,"Behavioral tracking"),i.a.createElement("p",null,"Brick and mortar retailers use computer vision algorithms in combination with store cameras to understand who their customers are and how they behave."),i.a.createElement("p",null,"Algorithms are able to recognize faces and ",i.a.createElement("b",null,"determine human characteristics"),", such as gender or age range. What\u2019s more, retailers can use computer vision techniques to ",i.a.createElement("b",null,"track customers\u2019 movements")," through stores, analyze navigational routes, detect walking patterns, and measure storefront attention times, as showed in this demo:"),i.a.createElement("div",{align:"center"},i.a.createElement("video",{controls:!0,src:"https://res.cloudinary.com/candicelin/video/upload/v1607826967/retail_zpjeri.mp4",type:"video/mp4"})),i.a.createElement("br",null),i.a.createElement("p",null,"Computer vision technology is able to analyze behavior patterns in the store and on this basis create heat-maps of stores. Thus, the analysis of customer behavior makes it possible to determine issues such as the best store layout to maximize profits, better product layout, which products should be added or what additional promotions should be considered. "),i.a.createElement("p",null,"In addition, computer vision is also an excellent tool for developing ",i.a.createElement("b",null,"anti-theft mechanisms"),". Among other things, face recognition algorithms can be trained to spot known shoplifters or to detect when someone is hiding an item in their backpack."),i.a.createElement("h2",null,"Inventory management"),i.a.createElement("p",null,"When it comes to inventory management, there are two main computer vision applications."),i.a.createElement("p",null,"Through security camera image analysis, a computer vision algorithm can generate a ",i.a.createElement("b",null,"very accurate estimate of the items available in the store"),". This is extremely valuable information for store managers, who can immediately become aware of an unusual increase in demand and react early and efficiently."),i.a.createElement("div",{align:"center"},i.a.createElement("img",{src:Q.a})," "),i.a.createElement("div",{class:"description"},"Another fairly common application is ",i.a.createElement("b",null,"analyzing the use of shelf space to identify suboptimal configurations"),". In addition to discovering lost space, an algorithm of this nature can suggest better item placement."),i.a.createElement("h2",null,"Vending store "),i.a.createElement("p",null,"Computer vision technology can be treated as a detection tool. The Amazon Go concept store in Seattle tracks shoppers using CV, with sensors on the shelves detecting when they pick up an item. It then registers all the items in the shopper\u2019s shopping basket with the Go mobile app, and does away with the checkout process altogether \u2013 the shopper simply leaves the shop, with the Go app taking the money automatically from the shopper\u2019s nominated credit card. The receipt is sent straight to the app."),i.a.createElement("div",{align:"center"},i.a.createElement("img",{src:D.a}))),i.a.createElement(p,null)))}}var M=Z,H=a(115),Y=a.n(H);class _ extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"fountain",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Healthcare"),i.a.createElement("h2",null,"Medical image analysis"),i.a.createElement("p",null,"In the healthcare domain, the number of existing computer vision applications is impressive."),i.a.createElement("p",null,"Undoubtedly, ",i.a.createElement("b",null,"medical image")," analysis is the best known example, since it helps to significantly improve the medical diagnostic process. Images from MRIs, CT scans, and X-rays are analyzed to find anomalies such as tumors or search for signs of neurological illnesses."),i.a.createElement("p",null,"In many cases, it\u2019s all about image analysis techniques, which extract features from images in order to train a classifier to be able to detect anomalies. However, there are specific applications where finer processing is required. For example, in the analysis of images from colonoscopies, it is necessary to segment the images to look for polyps and prevent colorectal cancer."),i.a.createElement("div",{align:"center"},i.a.createElement("img",{src:Y.a}),i.a.createElement("div",{class:"description"},"Volume segmentation of a 3D-rendered CT scan of the thorax")," "),i.a.createElement("p",null,"The image above is a result of image segmentation used to visualize thoracic elements. The system segments and colors each important part: the pulmonary arteries (blue), the pulmonary veins (red), the mediastinum (yellow), and the diaphragm (violet)."),i.a.createElement("p",null,"A large amount of applications of this type are currently in use, as varied as techniques that estimate the amount of blood lost due to postpartum hemorrhages; quantify coronary artery calcium; and evaluate blood flow in the human body without an MRI."),i.a.createElement("h2",null,"Medical Imaging"),i.a.createElement("p",null,"For the last decades, computer-supported medical imaging application has been a trustworthy help for physicians. It doesn\u2019t only create and analyze images, but also becomes an assistant and helps doctors with their interpretation. The application is used to read and convert 2D scan images into interactive 3D models that enable medical professionals to gain a detailed understanding of a patient\u2019s health condition."),i.a.createElement("h2",null,"Disease Diagnostics"),i.a.createElement("p",null,"Scientists are applying deep learning and natural language programming (NLP) systems to gather patient information, analyze patient\u2019s responses, and narrow down the diagnosis in a pre-appointment interview. The system sends these findings to the doctor before the patient comes in for the visit."),i.a.createElement("p",null,"Ellie, a computer vision program designed by scientists at the Institute of Creative Technologies at the University of Southern California, was built to do this. Ellie asks the patient a series of questions and, using the built-in webcam and sensor, scans the patient\u2019s face to assess their facial and body movements to formulate probable diagnoses."),i.a.createElement("p",null,"By comparing verbal cues as well as subtle facial and body movements with a dataset of thousands of control, Ellie can detect patients with mental health problems including depression and anxiety. While this program does not replace a human doctor, it provides subtle information that doctors may not easily elicit, improving the diagnosis of certain diseases."),i.a.createElement("p",null,"Babylon Health, a British tech startup, is also developing NLP and deep learning systems that use speech and language processing to extract symptoms and physical findings that are integral to formulating a diagnosis. These data are forwarded to a doctor to analyze before evaluating a patient."),i.a.createElement("p",null,"These algorithms not only use these patient data to make diagnoses, but they also provide personalized health information and education in greater detail than a doctor ever could.")),i.a.createElement(p,null)))}}var X=_,$=a(116),ee=a.n($);class te extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"fountain",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Manufacturing"),i.a.createElement("h2",null,"predictive maintenance"),i.a.createElement("p",null,"Major problems that can occur on a manufacturing line are the breaking of machines or the production of defective components. These result in delays and significant losses in profits."),i.a.createElement("p",null,"Computer vision algorithms prove to be a great means of ",i.a.createElement("b",null,"predictive maintenance"),". By analyzing visual information (e.g. from cameras attached to robots), algorithms can identify potential trouble before it occurs. The fact that a system can anticipate that a packaging or car assembly robot will fail is a huge contribution."),i.a.createElement("h2",null,"defect reduction"),i.a.createElement("p",null,"The same idea applies to ",i.a.createElement("b",null,"defect reduction"),", where the system can spot defects in components throughout the entire production line. This allows manufacturers to take actions in real time and decide what should be done to resolve the issue. Perhaps the defect is not so serious and the process can continue, but the product is flagged in some way or redirected through a specific production path. Sometimes, however, it may be necessary to stop the production line. Of further interest is that the system can be trained, for each use case, to classify the defects by types and degrees of severity."),i.a.createElement("h2",null,"Packaging Inspection"),i.a.createElement("div",{align:"center"},i.a.createElement("img",{src:ee.a})),i.a.createElement("br",null),i.a.createElement("p",null,"It is critical for pharmaceutical companies to count tablets or capsules before placing them into containers.  To solve this problem, Pharma Packaging Systems, who are based in England, has developed a solution that can be deployed to existing production lines or even ran as a standalone unit."),i.a.createElement("p",null,"A key feature of the solution involves using computer vision to check for broken or partially formed tablets.  As tablets make their way through the production line, pictures are taken and transferred to a dedicated PC that then processes the images using software which then runs further analysis to check if the tablets are the right color, length, width, and whole."),i.a.createElement("p",null,"The PC based Vision Inspection system is also implemented to a PC that performs the counting function and if a tablet is deemed as defective, this information is logged which then sends a signal to the counting functioning, and by the time the bottle of containers reaches the end of production line, containers that have defective tablets are then rejected, thereby removing the possibility of shipping defective medical tablets."),i.a.createElement("h2",null,"Reading barcodes"),i.a.createElement("p",null,"Reading, identifying and processing hundreds and thousands of barcodes per day is no easy task and something that humans simply cannot do at scale."),i.a.createElement("p",null,"For example, cell phones and mobile devices require smaller and smaller printed circuit boards (or PCBs).  As manufacturers are pressured to produce higher volumes of PCBs for the ever-growing tech market, they are looking towards a process known as \u201cpanelization\u201d.  In this process, a number of identical circuit boards are printed onto a large panel, each circuit is then separated by the machine for final testing, in order to inspect these boards, however, a machine vision-based solution called PanelScan was developed to read the barcodes \u2013 which are the unique identifiers of each circuit that is present on the PCN panel.")),i.a.createElement(p,null)))}}var ae=te,ne=a(117),ie=a.n(ne);class oe extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"fountain",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Autonomous vehicles"),i.a.createElement("div",{align:"center"},i.a.createElement("video",{controls:!0,src:"https://res.cloudinary.com/candicelin/video/upload/v1607827026/vehicle_dwuzw4.mp4",type:"video/mp4"})),i.a.createElement("br",null),i.a.createElement("p",null,"Have you ever wondered how self-driving cars can \u201csee\u201d? The field of computer vision plays a central role in the domain of autonomous vehicles, since it allows them to perceive and understand the environment around them in order to operate correctly."),i.a.createElement("p",null,"One of the most exciting challenges in computer vision is object detection in images and videos. This involves locating a varying number of objects and the ability to classify them, in order to distinguish if an object is a traffic light, a car, or a person, as in the video below."),i.a.createElement("div",{align:"center"},i.a.createElement("img",{src:ie.a})),i.a.createElement("div",{align:"center"},i.a.createElement("i",null,i.a.createElement("font",{color:"grey"},"Object detection for self-driving cars"))),i.a.createElement("br",null),i.a.createElement("p",null,"This kind of technology, combined with the analysis of data from other sources, such as sensors and/or radars, is what allows a car to \u201csee\u201d.")),i.a.createElement(p,null)))}}var se=oe;class le extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"fountain",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Insurance"),i.a.createElement("p",null,"The use of computer vision in insurance has had great impact, particularly in claims processing."),i.a.createElement("p",null,"A computer vision application can guide clients through the process of ",i.a.createElement("b",null,"visually documenting a claim"),". In real time, it can analyze images and send them to the appropriate agents. At the same time, it can estimate and adjust repair costs, determine if the insurance covers them and even check for possible fraud. All this minimizes the length of the claims cycle, resulting in a better client experience."),i.a.createElement("p",null,"From a preventive point of view, computer vision is of immense help in ",i.a.createElement("b",null,"avoiding accidents"),"; there are applications for preventing collisions, integrated into industrial machinery, cars, and drones. This is a new era of risk management that will most likely change the insurance field.")),i.a.createElement(p,null)))}}var re=le,ce=a(118),me=a.n(ce);class he extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"fountain",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Agriculture"),i.a.createElement("p",null,"Agriculture is a major industry where computer vision is having a tremendous impact, especially in the area of precision agriculture."),i.a.createElement("div",{align:"center"},i.a.createElement("img",{src:me.a})),i.a.createElement("p",null,"In ",i.a.createElement("b",null,"grain production"),", a global economic activity, a series of valuable applications have been developed. Grain production faces certain recurring issues, which historically have been monitored by humans. However, computer vision algorithms can now detect, or in some cases can reasonably predict, diseases or pest and insect infestations. Early diagnosis allows farmers to take appropriate measures quickly, reducing losses and ensuring production quality."),i.a.createElement("p",null,"Another permanent challenge is ",i.a.createElement("b",null,"weed control"),", considering that weeds have become resistant to herbicides over time and represent significant losses for farmers. There are robots with integrated computer vision technology that monitor an entire farm and spray herbicides precisely. This saves huge volumes of pesticides, which is an incredible benefit for the planet and in terms of production costs."),i.a.createElement("p",null,i.a.createElement("b",null,"Soil quality")," is likewise a major factor in agriculture. There are applications that can recognize, from images taken with mobile phones, potential defects and nutritional deficiencies in soils. After analyzing the images sent, these applications suggest soil restoration techniques and possible solutions to the problems detected."),i.a.createElement("p",null,"Computer vision can be further used in sorting. There are algorithms for sorting fruits, vegetables, and even flowers, by identifying their main properties (e.g. size, quality, weight, color, texture). These algorithms are additionally capable of spotting defects and estimating which items will last longer and which should be sent to local markets. This leads to the maximization of the shelf life of the items and reduces time-to-market.")),i.a.createElement(p,null)))}}var ue=he;class de extends i.a.Component{constructor(...e){super(...e),this.scrollToTop=()=>window.scrollTo(0,0)}render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement("div",{class:"body"},i.a.createElement(h.a,{type:"fountain",bg:!0}),i.a.createElement(f,null),i.a.createElement("div",{class:"page"},i.a.createElement("h1",null,"Defense and Security"),i.a.createElement("p",null,"Similar to the case of retailers, companies with high security requirements, such as banks or casinos, can benefit from computer vision applications that allow them to ",i.a.createElement("b",null,"identify customers")," based on analyzing images from security cameras."),i.a.createElement("p",null,"On another level, computer vision is a powerful ally in terms of ",i.a.createElement("b",null,"homeland security tasks"),". It can be used to improve cargo inspection at ports or for surveillance of sensitive places such as embassies, power plants, hospitals, railroads, and stadiums. The main idea in this context is that computer vision not only analyzes and classifies images, but can also build detailed and meaningful descriptions of a scene, providing, in real time, key elements for decision-makers."),i.a.createElement("p",null,"In general, computer vision is used extensively in ",i.a.createElement("b",null,"defense tasks")," such as reconnaissance of enemy terrain, automatic identification of enemies in images, automating vehicle and machine movements, and search and rescue.")),i.a.createElement(p,null)))}}var pe=de;a(198);class ge extends n.Component{constructor(e){super(e),this.state={page:!1},this.handleClick=this.handleClick.bind(this)}handleClick(){this.setState({page:!0})}render(){return this.state.page?i.a.createElement(m.a,{path:!0,to:"/homepage"}):i.a.createElement(i.a.Fragment,null,i.a.createElement(h.a,{type:"circle",num:50,bg:!0,position:"center"}),i.a.createElement("div",{class:"intro-container"},i.a.createElement("h1",null,"AN INTRODUCTORY GUIDE TO ",i.a.createElement("br",null),"COMPUTER VISION"),i.a.createElement("div",{class:"button shift-camera-button",onClick:this.handleClick},i.a.createElement("div",{class:"border"},i.a.createElement("div",{class:"left-plane"}),i.a.createElement("div",{class:"right-plane"})),i.a.createElement("div",{class:"text"},"Enter"))))}}var fe=ge;r.a.defaults.withCredentials=!0,r.a.defaults.headers.post["Content-Type"]="application/json";class Ee extends i.a.Component{render(){return i.a.createElement(i.a.Fragment,null,i.a.createElement(c.a,null,i.a.createElement(m.d,null,i.a.createElement(m.b,{path:"/",exact:!0,component:fe}),i.a.createElement(m.b,{exact:!0,path:"/homepage",component:b}),i.a.createElement(m.b,{exact:!0,path:"/topics/image-video-classification",component:j}),i.a.createElement(m.b,{exact:!0,path:"/topics/object-detection",component:q}),i.a.createElement(m.b,{exact:!0,path:"/topics/instance-segmentation",component:A}),i.a.createElement(m.b,{exact:!0,path:"/topics/image-video-enhancement",component:L}),i.a.createElement(m.b,{exact:!0,path:"/topics/generative-adversarial-networks",component:G}),i.a.createElement(m.b,{exact:!0,path:"/topics/object-tracking",component:B}),i.a.createElement(m.b,{exact:!0,path:"/applications/retail",component:M}),i.a.createElement(m.b,{exact:!0,path:"/applications/healthcare",component:X}),i.a.createElement(m.b,{exact:!0,path:"/applications/manufacturing",component:ae}),i.a.createElement(m.b,{exact:!0,path:"/applications/autonomous-vehicles",component:se}),i.a.createElement(m.b,{exact:!0,path:"/applications/insurance",component:re}),i.a.createElement(m.b,{exact:!0,path:"/applications/agriculture",component:ue}),i.a.createElement(m.b,{exact:!0,path:"/applications/defense-and-security",component:pe}),i.a.createElement(m.b,{render:function(){return i.a.createElement("h1",null,"Not Found")}}))))}}var be=Ee,ve=Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));function ye(e){navigator.serviceWorker.register(e).then(e=>{e.onupdatefound=()=>{var t=e.installing;t.onstatechange=()=>{"installed"===t.state&&(navigator.serviceWorker.controller?console.log("New content is available; please refresh."):console.log("Content is cached for offline use."))}}}).catch(e=>{console.error("Error during service worker registration:",e)})}s.a.render(i.a.createElement(be,null),document.getElementById("root")),function(){if("serviceWorker"in navigator){if(new URL("",window.location).origin!==window.location.origin)return;window.addEventListener("load",()=>{var e="".concat("","/service-worker.js");ve?function(e){fetch(e).then(t=>{404===t.status||-1===t.headers.get("content-type").indexOf("javascript")?navigator.serviceWorker.ready.then(e=>{e.unregister().then(()=>{window.location.reload()})}):ye(e)}).catch(()=>{console.log("No internet connection found. App is running in offline mode.")})}(e):ye(e)})}}()},98:function(e,t,a){e.exports=a.p+"static/media/classification.cae60c9f.png"}},[[122,1,2]]]);
//# sourceMappingURL=main.fda57ec8.chunk.js.map